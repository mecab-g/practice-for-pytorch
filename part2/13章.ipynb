{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d4f213-c3b6-4537-b3a6-2f9965c28625",
   "metadata": {},
   "source": [
    "##　セグメンテーション\n",
    "9から12章では分類機のモデル訓練に使用するデータは人手でアノテーションしている。\n",
    "モデルへの入力の結節を自動で生成したい。\n",
    "\n",
    "現実世界のアプローチでは複数の問題を個々のステップで解決するが、ディープラーニングの研究では複数の問題から構成されている問題を単一のモデルによって解決させる傾向がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadac47f-b2ef-45db-8644-4cae61b29e98",
   "metadata": {},
   "source": [
    "１３章ではCTスキャンの元データから結節である可能性がある領域を全て見つける。\n",
    "結節の一部であるボクセルに対してラベルをつけるセグメンテーション処理を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea29db6-3bf8-4cc2-b7bc-b1803266c18e",
   "metadata": {},
   "source": [
    "セマンティックセグメンテーション\n",
    "\n",
    "画像内の個々のピクセルに対してラベルをつける。今回は結節にTrue、正常組織にFalseのラベルをつける。\n",
    "\n",
    "\n",
    "物体検出\n",
    "\n",
    "画像内の対象にバウンディングボックスを設定する\n",
    "こちらの方が計算リソースが必要である"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e49a4ac-1b58-450d-ace6-f353089a13dd",
   "metadata": {},
   "source": [
    "## U-NET\n",
    "\n",
    "分類タスクでは画像を畳み込みとダウンサンプリングを繰り返し、各クラスの確率のベクトルにする。\n",
    "\n",
    "セグメンテーションでは入力と出力のサイズは同じにしたい。畳み込みによりテクスチャや色を検出し、ダウンサプリングによって畳み込みの受容野を広げ局所だけでなく広い特徴を掴む。このようにしていくと画像サイズが小さくなっていくので、1つのピクセルをn＊nのブロックに置き換えるアップサンプリングを行う。\n",
    "\n",
    "さらに今回はパディングをおこなことで、画像周辺のピクセルが失われないようにして、かつUのダウンサンプリング時とアップサンプリング時のサイズが同じになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a955a86-28fc-4251-ae38-49773a23a40a",
   "metadata": {},
   "source": [
    "スキップ接続がないと、ダウンサンプリング時に画像が小さくなり物体境界の正確な位置情報が失われやすくなる。\n",
    "\n",
    "U-Netのスキップ接続はResNetのスキップ接続とは異なり、ダウンサンプリング側の入力を対応する出力側のアップサンプリング側へつなぐ。\n",
    "このことにより、Uの底で広い受容野の情報とネットワーク初期の入力に近い高精細な情報の両方を出力へ繋げていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8a6dd-af39-4308-bc11-99b08fda2c6f",
   "metadata": {},
   "source": [
    "既存コードの再利用は良いアイデアだが、どのようなモデルで、どのような実装、訓練か取り組んでいるプロジェクトに適用できる部分があるか把握しておくことが必要。\n",
    "\n",
    "既存のモデルを変更していく場合は、1つずつ変更し比較していくと良い。\n",
    "\n",
    "今回は既存のU-NETから\n",
    "1：入力をバッチ正規化する\n",
    "2：出力の前にnn.sigmoidを使い[0,1]の範囲にする\n",
    "3：モデルの深さとフィルタを減らす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6203db-15e5-443d-ba30-273252f941ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUNetWrapper\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;66;03m# kwargs はコンストラクタに渡される全てのキーワード引数を含む辞書\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class UNetWrapper(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        # kwargs はコンストラクタに渡される全てのキーワード引数を含む辞書\n",
    "        super().__init__()\n",
    "\n",
    "        # BatchNorm2d は入力のチャンネル数を必要とする\n",
    "        # その情報をキーワード引数から取り出す\n",
    "        self.input_batchnorm = nn.BatchNorm2d(kwargs[\"in_channels\"])\n",
    "        # U-Netの取り込み部分はこれだけだが、ほとんどの処理はここで行われる\n",
    "        self.unet = UNet(**kwargs)\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "        # 第11章と同じように独自の重み初期化を行う\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        init_set = {\n",
    "            nn.Conv2d,\n",
    "            nn.Conv3d,\n",
    "            nn.ConvTranspose2d,\n",
    "            nn.ConvTranspose3d,\n",
    "            nn.Linear,\n",
    "        }\n",
    "        for m in self.modules():\n",
    "            if type(m) in init_set:\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight.data, mode=\"fan_out\", nonlinearity=\"relu\", a=0\n",
    "                )\n",
    "                if m.bias is not None:\n",
    "                    fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(\n",
    "                        m.weight.data\n",
    "                    )\n",
    "                    bound = 1 / math.sqrt(fan_out)\n",
    "                    nn.init.normal_(m.bias, -bound, bound)\n",
    "\n",
    "        # nn.init.constant_(self.unet.last.bias, -4)\n",
    "        # nn.init.constant_(self.unet.last.bias, 4)\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        bn_output = self.input_batchnorm(input_batch)\n",
    "        un_output = self.unet(bn_output)\n",
    "        fn_output = self.final(un_output)\n",
    "        return fn_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf54cd5-7890-4fec-8f77-bc3b54057485",
   "metadata": {},
   "source": [
    "今回の画像は三次元だが、nn.Batchnormは2d\n",
    "メモリ使用量を減らすためだが、前後の画像の情報は検出には必要。\n",
    "二次元画像として処理してセグメンテーション処理時には三次元画像として渡す。\n",
    "\n",
    "モデル学習時に自ら隣接していることを学ぶ必要があるが、z軸の画像量が少なく容易と考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076e7809-fd9e-426d-8c91-546e0a3e3e9c",
   "metadata": {},
   "source": [
    "画像のチャネルをスライス（＋2、＋1、0、-1、-2）に絞り、スライス、x軸、y軸の入力とする。\n",
    "スライス方向の情報を限定的にするが、結節の大きさは小さく今回の問題では十分だと判断。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0940c46-a95e-4fea-829e-e45dfffdedc4",
   "metadata": {},
   "source": [
    "## モデルの設計\n",
    "\n",
    "どのようなトレードオフを考えなけらばいけないかはフローチャートや経験則はないが、体系的に仮説を検証することが大切であり、\n",
    "思いつきの変更等は堪え、複数の変更を同時にテストすることはだめ。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9821d5-9bf3-46a2-bc1d-fb962a12cfea",
   "metadata": {},
   "source": [
    "## 正解データの作成\n",
    "\n",
    "1：バウンディングボックス\n",
    "\n",
    "結節の中心の位置はわかっているから、閾値以下になるまで左右、上下に探索し閾値以下になったらそこまでの範囲とする。\n",
    "他の組織と隣接している可能性もあるので、片方が低密度に触れたら探索終了となる。片方ずつの独立の探索はできず、結節は中心の情報が必要。\n",
    "\n",
    "下記のループ処理後にバウンディングボックス内の閾値より高い領域を調理和として取り出し、マスクとする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56e528-7492-45ab-af6a-2745e4b7ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAnnotationMask(self, positiveInfo_list, threshold_hu=-700):\n",
    "        # hu_aと同じ次元のゼロarrayを作成\n",
    "        boundingBox_a = np.zeros_like(self.hu_a, dtype=np.bool)\n",
    "\n",
    "        for candidateInfo_tup in positiveInfo_list:\n",
    "            center_irc = xyz2irc(\n",
    "                candidateInfo_tup.center_xyz,\n",
    "                self.origin_xyz,\n",
    "                self.vxSize_xyz,\n",
    "                self.direction_a,\n",
    "            )\n",
    "            \n",
    "            # 結節中心の位置情報\n",
    "            ci = int(center_irc.index)\n",
    "            cr = int(center_irc.row)\n",
    "            cc = int(center_irc.col)\n",
    "\n",
    "            index_radius = 2\n",
    "            try:\n",
    "                while (\n",
    "                    self.hu_a[ci + index_radius, cr, cc] > threshold_hu\n",
    "                    and self.hu_a[ci - index_radius, cr, cc] > threshold_hu\n",
    "                ):\n",
    "                    index_radius += 1\n",
    "            except IndexError:\n",
    "                index_radius -= 1\n",
    "                \n",
    "            row_radius = 2\n",
    "            try:\n",
    "                while (\n",
    "                    self.hu_a[ci, cr + row_radius, cc] > threshold_hu\n",
    "                    and self.hu_a[ci, cr - row_radius, cc] > threshold_hu\n",
    "                ):\n",
    "                    row_radius += 1\n",
    "            except IndexError:\n",
    "                row_radius -= 1\n",
    "\n",
    "            col_radius = 2\n",
    "            try:\n",
    "                while (\n",
    "                    self.hu_a[ci, cr, cc + col_radius] > threshold_hu\n",
    "                    and self.hu_a[ci, cr, cc - col_radius] > threshold_hu\n",
    "                ):\n",
    "                    col_radius += 1\n",
    "            except IndexError:\n",
    "                col_radius -= 1\n",
    "                \n",
    "                \n",
    "            \n",
    "            boundingBox_a[\n",
    "                ci - index_radius : ci + index_radius + 1,\n",
    "                cr - row_radius : cr + row_radius + 1,\n",
    "                cc - col_radius : cc + col_radius + 1,\n",
    "            ] = True\n",
    "        \n",
    "        # バウンディングボックスからマスクをくり抜く\n",
    "        mask_a = boundingBox_a & (self.hu_a > threshold_hu)\n",
    "\n",
    "        return mask_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9dbc324-b1f6-4538-90b8-5dcc18df3c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_221/1484239419.py:6: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  a=np.zeros_like(x,dtype=np.bool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.ones(27)\n",
    "x = x.reshape((3, 3, 3))\n",
    "x\n",
    "\n",
    "a=np.zeros_like(x,dtype=np.bool)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73f3dca9-2b13-4a83-ba78-aa54efd6af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1:2, 0:2, 1:2]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1decfca-889e-4dd5-a2a9-356a6807f780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False,  True, False],\n",
       "        [False,  True, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a16025-007c-43fd-a4fd-6cc5f981b1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
