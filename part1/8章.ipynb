{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206a74cb-b50f-43bf-98a1-5e8a68dd6685",
   "metadata": {},
   "source": [
    "## 畳み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef141348-455c-4b11-ab99-bc7cc4b58f9c",
   "metadata": {},
   "source": [
    "畳み込みとは\n",
    "\n",
    "あるピクセルと隣接するピクセルとの荷重和を作成する計算である。\n",
    "この計算により、局所的なパターンが画像内の物体位置に関わらず出力に効果的である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0225d1ac-db26-489f-8e3b-1d9a7736acb3",
   "metadata": {},
   "source": [
    "重み行列（カーネル）のスカラー積を出力していく\n",
    "カーネルサイズは一般的に小さなサイズを使用し、二次元画像には３＊３、RBGの画像には３＊３＊３のカーネルが使用される。\n",
    "\n",
    "カーネルの重みはnn.Linearの重みと同様に学習してい値である。そしてこのカーネルの重みは画像全体に渡り利用される。\n",
    "そのためカーネルの重みは画像全体から影響を受けることになる。\n",
    "\n",
    "全結合層を畳み込みに変更することで、下記のメリットがある\n",
    "\n",
    "１．近傍における局所的な演算処理\n",
    "２．移動不変性\n",
    "３．パラメータを大幅に削減したモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4b128-5758-4d21-b872-e166ee28b033",
   "metadata": {},
   "source": [
    "## 畳み込みの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89062e4c-15a3-4609-be26-0726003ef865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb6328-1ff1-4781-9a94-5186e075f26c",
   "metadata": {},
   "source": [
    "出力チャネルのサイズは任意の値が選択できる。\n",
    "このチャネルの数が増えるほどパラメータが増加し、特徴量の検出も増大する。\n",
    "\n",
    "カーネルのサイズはすべての方向に同じことが一般的だが、CTのボクセルのうち一つが異なる解像度であるような場合は、例外的に異なるサイズを使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46ca71f-ec15-43e7-8974-36bc85649f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f098af-ca60-46eb-af77-c687c78e39ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape, conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6ce25e-1e99-4090-a718-63e78ed435fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/p1ch7/\"\n",
    "#引数は保存のパス、訓練用かテスト用か、pytorchで保存して良いか\n",
    "#他にもSVHN ,COCO,Ominglotなどがある\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339322ae-9d9a-45bc-825c-3ce6b48648c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = datasets.CIFAR10(\n",
    "            data_path, train=True, download=False, \n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                     (0.1470, 0.2435, 0.2626))\n",
    "            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bff76a8-5769-4871-8fbe-1f27b4d96fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16084e3d-6b95-4124-8320-37d13e8a3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cifar10の中から飛行機と鳥のみのdatasetsにする\n",
    "label_map = {0:0, 2:1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0,2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdde8ad0-c36d-466d-a01d-9efd43a2df14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ffc773-c831-4af5-a87c-5c1bfaef735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze((0)).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eeeb722-93b5-4272-bb31-b8cd35e5734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 30])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead3d316-5856-4106-be82-411b76e4df8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "_peLHw3CTeVC",
    "outputId": "950db33c-99fd-45d8-b274-6d66225182c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x345.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4.8))  # 本では省略\n",
    "ax1 = plt.subplot(1, 2, 1)   # 本では省略\n",
    "plt.title('output')   # 本では省略\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)  # 本では省略\n",
    "plt.imshow(img.mean(0), cmap='gray')  \n",
    "plt.title('input')  # 本では省略\n",
    "#plt.savefig('Ch8_F2_PyTorch.png')  # 本では省略\n",
    "plt.show()\n",
    "\n",
    "#sharex = XXX：x軸の共有設定\n",
    "#sharey = XXX：y軸の共有設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba6848-48c3-45d9-b4a8-d988d10befa1",
   "metadata": {},
   "source": [
    "入力に対して出力の画像サイズが小さくなっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d517a79-f790-4065-bfd5-6166b812e6e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 境界のパディング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8471318-5f88-4142-91bd-ae77a18a7056",
   "metadata": {},
   "source": [
    "畳み込み処理では全ての方向に隣接したピクセルが存在する必要がある。\n",
    "角の位置では上下どちらか、左右どちらかが存在しない。デフォルトではPyTorchではwidth - kernl_width +1 の位置までを取得する。\n",
    "奇数サイズのカーネルではカーネルの幅の半分（今回は3//2=1)だけ各境界が小さくなった画像が出力された。\n",
    "\n",
    "pytorchでは畳み込み時に境界領域にゼロになｋる架空のピクセルを作成して画像をパディングできる。\n",
    "今回の件ではkernel_size=3*3, padeing=1 を指定するともとの画像と同じサイズの出力が得られる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f3df62-e207-48ea-9bf4-839795171ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "output = conv(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a042ed4-eb43-490d-be69-f61dfb8f906a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 1, 32, 32]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c871475-c0d3-4d9a-9073-1bfcbf6778f6",
   "metadata": {},
   "source": [
    "画像サイズが変化しないことはスキップ接続や複雑な構造のモデルでテンソル同士の加減算が可能になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c58b7-9e45-4e97-b6a2-cb41f49438e1",
   "metadata": {},
   "source": [
    "## 畳み込みの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14e9a9-fd4d-4023-b675-9b82419036a4",
   "metadata": {},
   "source": [
    "手動でのパラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "012d6d06-5619-4ff3-b3f2-f53103a1e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#バイアスをゼロにする\n",
    "with torch.no_grad():\n",
    "    conv.bias.zero_()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089f9515-03f2-4536-88be-034c4a0f0ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111]],\n",
       "\n",
       "         [[0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111]],\n",
       "\n",
       "         [[0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111]]]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4f0de35-65fe-4bfc-a08c-b2ec9f23db88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "VUQhUyEoTeVT",
    "outputId": "024b9a6a-2d2e-4863-ea9a-a26b7820192c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x345.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.figure(figsize=(10, 4.8))  # 本では省略\n",
    "ax1 = plt.subplot(1, 2, 1)   # 本では省略\n",
    "plt.title('output_padding')   # 本では省略\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)  # 本では省略\n",
    "plt.imshow(img.mean(0), cmap='gray')  # 本では省略\n",
    "plt.title('input')  # 本では省略\n",
    "#plt.savefig('Ch8_F4_PyTorch.png')  # 本では省略\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe5b4e-1501-4bd2-a497-b5a173746a67",
   "metadata": {},
   "source": [
    "convの一定の重み（フィルタ）によってボケた画像が出力された。\n",
    "畳み込みは出力ピクセル間に相関が生まれ、スムーズに画像が変化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cfd4753-f449-496d-b86b-3c17471a111d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09045477-1f06-4b11-9aab-b9430dec94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#右側のピクセルから左側のピクセルを減算するフィルタ\n",
    "#強度が異なる領域の垂直方向の境界になっているピクセルに対しては出力の値は大きな値となる。\n",
    "#一方一様な領域であれば0に近い値となる。\n",
    "\n",
    "#つまり垂直方向のエッジ検出のカーネルとなる\n",
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0]])\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6deed91-a931-4380-b63d-821af7872626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.]],\n",
       "\n",
       "         [[-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.]],\n",
       "\n",
       "         [[-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e408be0-467d-47a9-aabe-173022526ebb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "VUQhUyEoTeVT",
    "outputId": "024b9a6a-2d2e-4863-ea9a-a26b7820192c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x345.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.figure(figsize=(10, 4.8))  # 本では省略\n",
    "ax1 = plt.subplot(1, 2, 1)   # 本では省略\n",
    "plt.title('output_padding')   # 本では省略\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)  # 本では省略\n",
    "plt.imshow(img.mean(0), cmap='gray')  # 本では省略\n",
    "plt.title('input')  # 本では省略\n",
    "#plt.savefig('Ch8_F4_PyTorch.png')  # 本では省略\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b99283-9585-48c4-9b4c-eadee1fb9783",
   "metadata": {},
   "source": [
    "ディープラーニングでは最も効果的なカーネルの値を推定する。\n",
    "学習は入力と出力の間のクロスエントロピー誤差を最小化するカーネルの値を推測していく。\n",
    "\n",
    "畳み込みニューラルネットワークは複数チャネルの画像を別の複数チャネルの画像に変換する連続した層のフィルタ群を推定することである。\n",
    "この異なるチャネルは異なる特徴量に対応する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb7802-dd64-4374-9605-f4f4f67cad8d",
   "metadata": {},
   "source": [
    "## 深さとプーリング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc64dc-7596-436d-8380-b4ffc1dbc926",
   "metadata": {},
   "source": [
    "CIFAR10の画像は小さく小さなカーネルで局所的な特徴を得た。\n",
    "大きな画像で広い範囲の構造を把握したい場合はどうすれば良いか？\n",
    "\n",
    "大きなカーネルを使用することで解決できるが、今度は元々の畳み込みの利点がなくなる。\n",
    "\n",
    "畳み込みの利点を活かし、かつ大きな範囲の構造も把握するためには畳み込み後に畳み込みを繰り返しその間にダウンサンプリングをする方法がある"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a966e-83d5-4ca1-b656-f4ba4e110393",
   "metadata": {},
   "source": [
    "## ダウンサンプリング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3473a2d4-025b-407a-b5b1-5a1123196539",
   "metadata": {},
   "source": [
    "画像を半分に縮小することは隣接している4つのピクセルを1つのピクセルにする\n",
    "\n",
    "1.アベレージプーリング\n",
    "2.マックスプーリング\n",
    "3.ストライド畳み込み\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cbe6c33-e776-41dc-a283-dcef574ae5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85042ab7-95d4-4fa8-ab0d-cfced71abaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_pooling\n",
    "#画像を半分にしたいときはインスタンス引数に2を入れる\n",
    "\n",
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape , output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbcbad-3645-49fa-9b3c-37f30fb95752",
   "metadata": {},
   "source": [
    "はじめに小さなカーネルで畳み込みを行い、局所の特徴を掴み、\n",
    "ダウンサンプリングした縮小後の画像で畳み込みを行う（元の画像で考えると倍の広い領域の特徴を掴む）\n",
    "\n",
    "1つ目のカーネルは低レベルの特徴を、2つ目のカーネルは広い領域で効果的に動作し、前の特徴量を合成した特徴量を生成する。\n",
    "\n",
    "このため複雑なケースでも対応できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0324e7d-3edb-4a85-a66c-c79b7a6e2df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Tanh()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): Tanh()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ダウンサンプリングを入れたモデル\n",
    "model = nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb4ed49c-7a95-49fb-8305-52dddb881eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出力は8チャネルの8＊8の画像\n",
    "model(img.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1996cdde-3138-4e5c-8491-8c46054cec08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Tanh()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): Tanh()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (7): Tanh()\n",
       "  (8): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出力はとりか飛行機の2値にする必要がある\n",
    "# 画像を32のベクトルにして、最後2値にする\n",
    "model = nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Linear(8 * 8 * 8, 32),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(32, 2)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df6306dc-9014-402e-bd3e-cab453fa9e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パラメータ確認\n",
    "num_list = [p.numel() for p in model.parameters()]\n",
    "sum(num_list), num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e1edc5ef-b30c-4a74-8ddd-7ff4fff2097d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x8 and 512x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#エラーが出る\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x8 and 512x32)"
     ]
    }
   ],
   "source": [
    "#エラーが出る\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a43077c-fd2e-4a99-aa98-bdbc104d1980",
   "metadata": {},
   "source": [
    "## nn.Moduleを継承してモデルを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62504e0d-d4b8-4e91-8214-6b32bd0834e3",
   "metadata": {},
   "source": [
    "モデル内で入力が二次元から一次元へと形式が変化するような場合はnn.sequeintal()では作成できない\n",
    "（次元数が変化しないモデルを作成し。最後にLinearする手もある：キカガク参考）\n",
    "\n",
    "nn.Moduleのサブクラス(子クラス）を用いて作成する\n",
    "\n",
    "nn.Moduleを用いる場合はfoward関数を定義して、入力か出力への流れを記載する。\n",
    "backwardはtorchのテンソルでは自動でおこなってくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "525974cd-7b6c-408e-9af6-e5bfcdb3930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# バッチ数が不明のためviewの引数は-1\n",
    "# CNNの有名なモデルRESNETなどでは解像度を落としながら、チャネルを増やしていく（結果的にはサイズは縮小する）　\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffa8d1e4-af22-4a1b-9aa5-16deee5cabb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1170f-a58c-4e6d-8bf8-abcf5bca6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f51a3-6e98-4e1a-b600-4f758749b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb71a11-4830-4476-b328-bd7ae5571f55",
   "metadata": {},
   "source": [
    "## functional API\n",
    "\n",
    "パラメータが不要なサブモジュールも上の例ではインスタンス化して登録している。\n",
    "pytorchでは「内部状態を持たない」といういみのfanctonalAPIが存在し、入力値を引数に入れると出力値が決定するモジュールがある。\n",
    "\n",
    "nn.Linear には　nn.fanctional.linear 　　重みとバイアスと入力値を引数に入れて出力値が決まる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c3118a26-75e2-4190-b897-435de7f93122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9eef8c95-20d5-4d34-86eb-f828c36a53bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1443, -0.3033]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aef8c4-9566-4a48-83b0-6fdc6f6e3054",
   "metadata": {},
   "source": [
    "## 畳み込みニューラルネットの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e0da96-8781-4e56-96e6-138a62557fe8",
   "metadata": {},
   "source": [
    "ネットワークは外側がエポック、内側がバッチを取り出すDataLoaderによって二重にネストされている\n",
    "\n",
    "各訓練ループは\n",
    "\n",
    "１．入力をモデルに与える\n",
    "\n",
    "２．損失を計算する\n",
    "\n",
    "３．勾配をゼロにする（リセット）\n",
    "\n",
    "４．loss.backfoward()ですべてのパラメータの損失に対する勾配を計算\n",
    "\n",
    "５．オプティマイザで損失を低下する方向に更新\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "958b331a-e4db-489f-9210-8a5ec63beab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lossまでの確認\n",
    "img, label = cifar2[0]\n",
    "label = torch.tensor([label])\n",
    "label.shape\n",
    "#labelはバッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8a0a2dc4-e0ba-4541-ba1e-d53189b40689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(img.unsqueeze(0))\n",
    "output.shape\n",
    "#outputはバッチ　＊　答えの種類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dce09518-4155-4737-bc3d-c23934dd02cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9418, grad_fn=<NllLossBackward0>) 0.9417555332183838\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#確率が高い方とラベルとの損失\n",
    "loss = loss_fn(output, label)\n",
    "print(loss, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f581d92d-a3e7-4c13-b2f0-8b55d7d767f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # <1>\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):  # <2>\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  # <3>\n",
    "            outputs = model(imgs)  # <4>\n",
    "            loss = loss_fn(outputs, labels)  # <5>\n",
    "            optimizer.zero_grad()  # <6>            \n",
    "            loss.backward()  # <7>\n",
    "            optimizer.step()  # <8>\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  # <10>\n",
    "            # <1>\n",
    "# Pythonに含まれているdatetimeモジュールを使用 \n",
    "# \n",
    "# <2>\n",
    "# 0からではなく1からn_epochsまで数字を振ったエポックに対するループ\n",
    "# \n",
    "# <3>\n",
    "# データローダーが作成したバッチの中のデータセットに対するループ\n",
    "# \n",
    "# <4>\n",
    "# モデルにバッチを投入し、…\n",
    "# \n",
    "# <5>\n",
    "# … そして最小化したい損失を計算を行う。\n",
    "# \n",
    "# <6>\n",
    "# 直近のラウンドの勾配を取り除いたあとに…\n",
    "# \n",
    "# <7>\n",
    "# … バックワード処理を行う。 \n",
    "# つまり、ネットワークに学習して欲しいすべての パラメーターの勾配を計算します。\n",
    "# \n",
    "# <8>\n",
    "# モデルを更新\n",
    "# \n",
    "# <9>\n",
    "# エポックをまたいで損失を合算。 \n",
    "# 勾配の情報を除くため、損失の値を.item()を用いて \n",
    "# Pythonの数値に変形するということを覚えておきましょう。 \n",
    "# \n",
    "# <10>\n",
    "# 訓練用のデータローダーの長さで除算し、バッチあたりの平均損失を得ます。 \n",
    "# これは合計値よりも直感的な尺度ですね。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7986590e-e784-4fe6-952a-37010adbe81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-03 18:48:21.789566 Epoch 1, Training loss 0.5550007694845747\n",
      "2022-08-03 18:48:43.828336 Epoch 10, Training loss 0.3131621859160958\n",
      "2022-08-03 18:49:10.032463 Epoch 20, Training loss 0.2806974172022692\n",
      "2022-08-03 18:49:36.395794 Epoch 30, Training loss 0.25288414831753747\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)  # <1>\n",
    "\n",
    "model = Net()  #  <2>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
    "\n",
    "training_loop(  # <5>\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "# <1>\n",
    "# DataLoaderがcifar2のデータセットのサンプルをバッチ化します。 \n",
    "# また、データセットからサンプルを取得する順番をランダムにシャッフルしています。 \n",
    "# <2>\n",
    "# ネットワークをインスタンス化し、…\n",
    "# <3>\n",
    "# … 扱った確率的勾配降下の最適化関数を使用し…\n",
    "# <4>\n",
    "# … 7.10節で扱った交差エントロピー損失を使用。\n",
    "# <5>\n",
    "# 先程定義した訓練ループを呼び出す。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b87155-3a99-4ca6-8cdb-a17dafc6efee",
   "metadata": {},
   "source": [
    "訓練の損失は低下したがそれだけでは評価できない\n",
    "\n",
    "評価指標が必要であるため、正解率で確認してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eae15868-db04-4210-9676-94ab31275624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.89\n",
      "Accuracy val: 0.85\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "import collections\n",
    "\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict={}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # パラメータの更新は不要のためlossは確認しない、勾配も不要\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada9fc1e-3893-4695-a7a3-fde7e9da1d42",
   "metadata": {},
   "source": [
    "##　モデルの保存と読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e32b1954-b534-42d9-8712-95bb810b6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # モデルの保存\n",
    "data_path = '.'\n",
    "\n",
    "torch.save(model.state_dict(), data_path + \"birds_vs_airplanes.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ad7de-0fa2-4fa3-974f-3e4325d38aff",
   "metadata": {},
   "source": [
    "この方法でモデルを保存したときはモデル内のパラメータと（重みとバイアス）であって、\n",
    "モデルの構造は保存されていない。\n",
    "\n",
    "読み込み時にモデルは同一のモデルをインスタンス化してパラメータを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "44448ddb-fa62-49b0-a5f5-89c0fefa6bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # モデルの読み込み\n",
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load(data_path + 'birds_vs_airplanes.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4f9c5-099e-4d42-b9fa-dd2f0b1de2f1",
   "metadata": {},
   "source": [
    "## GPU上での訓練\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81946a-8824-4f24-b8c2-cc70ec6bc734",
   "metadata": {},
   "source": [
    ".toメソッドを使えばテンソルをGPUへ移動できる。モデルのパラメータもGPUに移し計算をGPU上で行う。\n",
    "\n",
    "Module.toはそのインスタンスそのものが移動する。\n",
    "\n",
    "Tensor.toは別メモリ上での処理となり、あらたなテンソルが返される\n",
    "\n",
    "モデルは適当なデバイスにパラメータを移してからOptimaizerを作成するのがよい。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ef0cdca4-4559-40e2-9070-2b6c77ded67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "\n",
    "print(f'Training on device {device}.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "22f9b575-650d-4523-ad10-3a1b9c836b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUでの学習でも対応\n",
    "# 全てのパラメータがGPUに無い場合はエラー（一部GPUでの計算は非対応）\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device) \n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fc499cbd-abb3-40a9-868e-067bf79d6589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-03 18:51:59.789856 Epoch 1, Training loss 0.5792931413194936\n",
      "2022-08-03 18:52:19.928191 Epoch 10, Training loss 0.3215153699467896\n",
      "2022-08-03 18:52:42.754177 Epoch 20, Training loss 0.28650582121436\n",
      "2022-08-03 18:53:06.255702 Epoch 30, Training loss 0.26049129626933176\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b53b8d01-9a5a-4010-be0c-6eec8c92de22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EeffUEkETeW7",
    "outputId": "c9b9845d-0526-41f8-e00e-c04e064d155d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorchではネットワークの重み等の読み込み時は保存時のデバイスに読み込もうとする。\n",
    "# ネットワークの重みを読み込むデバイスと保存されているデバイスが同じなのか事前には分からないため指示する　map_loacation\n",
    "loaded_model = Net().to(device=device)\n",
    "loaded_model.load_state_dict(torch.load(data_path\n",
    "                                        + 'birds_vs_airplanes.pt',\n",
    "                                        map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b33b1e-1034-489d-ab20-a4c0ccf2efba",
   "metadata": {},
   "source": [
    "##　モデルの改善：幅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b833710-8056-41a5-be86-8c88438f454c",
   "metadata": {},
   "source": [
    "記憶容量の追加時にハードコーティングを避けるためには、initにパラメータを渡す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2f9c380d-f7ea-4161-827c-7aa1571f01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWidth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1 \n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5d427dbc-5502-49a9-85e0-2e91b8437718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-03 18:53:11.166242 Epoch 1, Training loss 0.5420930154004674\n",
      "2022-08-03 18:53:50.312736 Epoch 10, Training loss 0.3054007347791817\n",
      "2022-08-03 18:54:34.737708 Epoch 20, Training loss 0.2690998776133653\n",
      "2022-08-03 18:55:18.574086 Epoch 30, Training loss 0.2373451960219699\n",
      "Accuracy train: 0.88\n",
      "Accuracy val: 0.81\n"
     ]
    }
   ],
   "source": [
    "model = NetWidth(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "all_acc_dict[\"width\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc797468-d440-4a89-8be2-3ab4b826c9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38386"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8561d567-1686-4db1-808a-ac92b2c8c235",
   "metadata": {},
   "source": [
    "モデル内の容量が増加するほどモデルが管理できる入力の可能性は高くなる。\n",
    "しかし同時に不要な側面を記憶するパラメータをモデルが多数使用することになり、過学習が起きやすい。\n",
    "\n",
    "過学習にはサンプルサイズの拡大、DataAugmentationが有効だが、モデルレベルでの制御法もある"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f52f6-e837-482a-94e9-e6d81aa48c98",
   "metadata": {},
   "source": [
    "## 損失時に改善　正則化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6d3ea-9002-4167-9188-21a126306bf7",
   "metadata": {},
   "source": [
    "損失に正則化項（重みパラメータを足したもの）を加えることで、大きな値の重みへのペナルティになる。\n",
    "損失関数はより滑らかになり、個々のサンプルに過剰に適合することを防ぐ。\n",
    "\n",
    "L2：モデル内の重みの二乗をすべて足したもの\n",
    "重みの減衰（現在の値に比例した量だけ各重みを減衰させる）\n",
    "\n",
    "L1：モデル内の重みの絶対値をすべて足したもの\n",
    "重みを0に近づけるため不要なパラメータを無くす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8ab18c1-90af-44cb-8526-b0b8a2c7344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs +1 ):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            l2_lambda = 0.01\n",
    "            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "            #l1はpoe(2.0)をabs()\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch, loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f1bc5b6-d108-42b6-a77d-aa23392ea245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-03 18:55:23.691783 Epoch 1, Training loss 0.8086239376645179\n",
      "2022-08-03 18:55:44.398025 Epoch 10, Training loss 0.4812535391112042\n",
      "2022-08-03 18:56:06.990436 Epoch 20, Training loss 0.4167952366695283\n",
      "2022-08-03 18:56:29.264931 Epoch 30, Training loss 0.38513967081619677\n",
      "Accuracy train: 0.86\n",
      "Accuracy val: 0.85\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop_l2reg(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "all_acc_dict[\"l2 reg\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69811006-8552-44c5-8596-a319c6af1611",
   "metadata": {},
   "source": [
    "## ドロップアウト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99315bc-27a6-44f9-98c8-7568e1f48d38",
   "metadata": {},
   "source": [
    "ネットワーク上の出力をランダムの割合でゼロにする\n",
    "各反復で異なるニューロンの形状のわずかに異なるモデルが作成されるため、モデル内のニューロンが記憶プロセスになることを防ぐ。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9347e7-0036-4f52-b16c-00245964bb90",
   "metadata": {},
   "source": [
    "このドロップアウトは訓練時のみ有効であり、推論時はモードを切り替えて全パラメータを使用する。\n",
    "\n",
    "model.train()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "で切り替え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aadbac98-3189-476c-9b68-424af263636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2444fb8-df7a-402a-b971-c1b5598b3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-03 19:12:19.405519 Epoch 1, Training loss 0.5819971483604164\n",
      "2022-08-03 19:13:03.441345 Epoch 10, Training loss 0.3753346732467603\n",
      "2022-08-03 19:13:51.085962 Epoch 20, Training loss 0.3377366876051684\n"
     ]
    }
   ],
   "source": [
    "model = NetDropout(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "\n",
    "all_acc_dict[\"dropout\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f142ec20-843a-42e3-bdc6-92639c065da0",
   "metadata": {},
   "source": [
    "## バッチ正則化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f106b6d-151f-41dc-96c0-554c97a5f59c",
   "metadata": {},
   "source": [
    "活性化に対する入力を特定の分布内にリスケールする。\n",
    "入力が活性化関数の飽和部分へ極端に移動することを防ぎ訓練が遅くなることを防ぐ。\n",
    "\n",
    "ミニバッチごとにネットワークの中間地点で入力値の平均値と標準偏差を使用して中間入力の大きさにシフトする。\n",
    "\n",
    "正則化とデータオーギュメンテーションの意味がある\n",
    "\n",
    "基本的には活性化関数の前に使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4917a-dfb4-4f0a-9e4d-53f11f505746",
   "metadata": {},
   "source": [
    "推論時はモードを切り替えることで、訓練時のデータセット全体の平均値と標準偏差を毎回使用するようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0a6aa-8d03-4729-8335-86efbe5cf32e",
   "metadata": {
    "id": "aaVSP0vGTeXl"
   },
   "outputs": [],
   "source": [
    "class NetBatchNorm(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, \n",
    "                               padding=1)\n",
    "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.conv2_batchnorm(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82014495-f111-471e-a2c9-e1cf2c42168c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "tpjdjqfaTeXo",
    "outputId": "c846e757-3f21-491d-e9cf-6e5dbb9c7f75"
   },
   "outputs": [],
   "source": [
    "model = NetBatchNorm(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "all_acc_dict[\"batch_norm\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844e24c-cd96-4ffd-9939-e0c250760b09",
   "metadata": {},
   "source": [
    "## モデル改善：深さ　接続"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd5ab5-4cbc-44e8-a670-991790dff5e3",
   "metadata": {},
   "source": [
    "接続の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4905db45-a3d8-45cb-b7f8-052b34de4127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.3447],\n",
       "         [0.6226]]),\n",
       " tensor([[ 0.8658],\n",
       "         [-0.6243]]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_a = torch.randn(2,1)\n",
    "batch_b = torch.randn(2,1)\n",
    "batch_a, batch_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "57a34d23-9c93-43da-a24a-1622550b012b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2105e+00],\n",
       "        [-1.7257e-03]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_a + batch_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "00238ca1-c6d7-49b7-bf7e-6cf976c65f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3, 5)\n",
    "nn.init.constant_(w, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421252a9-911c-4451-ba78-4428090b027b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b54973-9567-4584-bda8-b5518f1f5716",
   "metadata": {
    "id": "NjWrXybDTeX2"
   },
   "outputs": [],
   "source": [
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd85db3-d0ab-492d-b221-99b400c54734",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "KfgqWhcwTeX6",
    "outputId": "fafaf0f3-4a4f-497a-ce84-702e25bbda0f"
   },
   "outputs": [],
   "source": [
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "all_acc_dict[\"res\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a8792-a9c6-4435-bd2c-7e923c485eb5",
   "metadata": {
    "id": "lNqv3CZgTeX9"
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                              padding=1, bias=False)  # <1>\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                      nonlinearity='relu')  # <2>\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "\n",
    "# <1>\n",
    "# BatchNorm層はバイアスの影響を消し去るため、慣例的にバイアスは省いています。 \n",
    "# \n",
    "# <2>\n",
    "# ResNetの論文で計算されている標準偏差を持つ正規の乱数を用いたカスタマイズの初期化処理 kaiming_normal_initializes を使用します。 \n",
    "# なお、初期状態では、バッチ正規化処理は平均0で分散0.5の出力分布を生成するように初期化されます。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34130157-1722-4f5e-b2b3-8ba566d15c44",
   "metadata": {
    "id": "rRHc8xfWTeYD"
   },
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ac5e2-e059-4ac2-900b-009b5c06c06d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "TkiMOWJfTeYF",
    "outputId": "b426481a-78c9-4e14-f3e5-522124599bb1"
   },
   "outputs": [],
   "source": [
    "model = NetResDeep(n_chans1=32, n_blocks=100).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "all_acc_dict[\"res deep\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e298f23-4f64-4144-b071-8400bf068719",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "X8ZExdRETeYN",
    "outputId": "7c0e9564-e4d1-446b-93c6-2bed99a40df1"
   },
   "outputs": [],
   "source": [
    "trn_acc = [v['train'] for k, v in all_acc_dict.items()]\n",
    "val_acc = [v['val'] for k, v in all_acc_dict.items()]\n",
    "\n",
    "width =0.3\n",
    "plt.bar(np.arange(len(trn_acc)), trn_acc, width=width, label='train')\n",
    "plt.bar(np.arange(len(val_acc))+ width, val_acc, width=width, label='val')\n",
    "plt.xticks(np.arange(len(val_acc))+ width/2, list(all_acc_dict.keys()),\n",
    "           rotation=60)\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0.7, 1)\n",
    "plt.savefig('accuracy_comparison.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
