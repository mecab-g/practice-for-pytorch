{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206a74cb-b50f-43bf-98a1-5e8a68dd6685",
   "metadata": {},
   "source": [
    "## 畳み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef141348-455c-4b11-ab99-bc7cc4b58f9c",
   "metadata": {},
   "source": [
    "畳み込みとは\n",
    "\n",
    "あるピクセルと隣接するピクセルとの荷重和を作成する計算である。\n",
    "この計算により、局所的なパターンが画像内の物体位置に関わらず出力に効果的である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0225d1ac-db26-489f-8e3b-1d9a7736acb3",
   "metadata": {},
   "source": [
    "重み行列（カーネル）のスカラー積を出力していく\n",
    "カーネルサイズは一般的に小さなサイズを使用し、二次元画像には３＊３、RBGの画像には３＊３＊３のカーネルが使用される。\n",
    "\n",
    "カーネルの重みはnn.Linearの重みと同様に学習してい値である。そしてこのカーネルの重みは画像全体に渡り利用される。\n",
    "そのためカーネルの重みは画像全体から影響を受けることになる。\n",
    "\n",
    "全結合層を畳み込みに変更することで、下記のメリットがある\n",
    "\n",
    "１．近傍における局所的な演算処理\n",
    "２．移動不変性\n",
    "３．パラメータを大幅に削減したモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4b128-5758-4d21-b872-e166ee28b033",
   "metadata": {},
   "source": [
    "## 畳み込みの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89062e4c-15a3-4609-be26-0726003ef865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb6328-1ff1-4781-9a94-5186e075f26c",
   "metadata": {},
   "source": [
    "出力チャネルのサイズは任意の値が選択できる。\n",
    "このチャネルの数が増えるほどパラメータが増加し、特徴量の検出も増大する。\n",
    "\n",
    "カーネルのサイズはすべての方向に同じことが一般的だが、CTのボクセルのうち一つが異なる解像度であるような場合は、例外的に異なるサイズを使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46ca71f-ec15-43e7-8974-36bc85649f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f098af-ca60-46eb-af77-c687c78e39ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape, conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6ce25e-1e99-4090-a718-63e78ed435fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/p1ch7/\"\n",
    "#引数は保存のパス、訓練用かテスト用か、pytorchで保存して良いか\n",
    "#他にもSVHN ,COCO,Ominglotなどがある\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339322ae-9d9a-45bc-825c-3ce6b48648c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = datasets.CIFAR10(\n",
    "            data_path, train=True, download=False, \n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                     (0.1470, 0.2435, 0.2626))\n",
    "            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bff76a8-5769-4871-8fbe-1f27b4d96fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16084e3d-6b95-4124-8320-37d13e8a3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cifar10の中から飛行機と鳥のみのdatasetsにする\n",
    "label_map = {0:0, 2:1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0,2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdde8ad0-c36d-466d-a01d-9efd43a2df14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ffc773-c831-4af5-a87c-5c1bfaef735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze((0)).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eeeb722-93b5-4272-bb31-b8cd35e5734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 30])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead3d316-5856-4106-be82-411b76e4df8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "_peLHw3CTeVC",
    "outputId": "950db33c-99fd-45d8-b274-6d66225182c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x345.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4.8))  # 本では省略\n",
    "ax1 = plt.subplot(1, 2, 1)   # 本では省略\n",
    "plt.title('output')   # 本では省略\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)  # 本では省略\n",
    "plt.imshow(img.mean(0), cmap='gray')  \n",
    "plt.title('input')  # 本では省略\n",
    "#plt.savefig('Ch8_F2_PyTorch.png')  # 本では省略\n",
    "plt.show()\n",
    "\n",
    "#sharex = XXX：x軸の共有設定\n",
    "#sharey = XXX：y軸の共有設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba6848-48c3-45d9-b4a8-d988d10befa1",
   "metadata": {},
   "source": [
    "入力に対して出力の画像サイズが小さくなっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d517a79-f790-4065-bfd5-6166b812e6e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 境界のパディング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8471318-5f88-4142-91bd-ae77a18a7056",
   "metadata": {},
   "source": [
    "畳み込み処理では全ての方向に隣接したピクセルが存在する必要がある。\n",
    "角の位置では上下どちらか、左右どちらかが存在しない。デフォルトではPyTorchではwidth - kernl_width +1 の位置までを取得する。\n",
    "奇数サイズのカーネルではカーネルの幅の半分（今回は3//2=1)だけ各境界が小さくなった画像が出力された。\n",
    "\n",
    "pytorchでは畳み込み時に境界領域にゼロになｋる架空のピクセルを作成して画像をパディングできる。\n",
    "今回の件ではkernel_size=3*3, padeing=1 を指定するともとの画像と同じサイズの出力が得られる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f3df62-e207-48ea-9bf4-839795171ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "output = conv(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a042ed4-eb43-490d-be69-f61dfb8f906a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 1, 32, 32]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c871475-c0d3-4d9a-9073-1bfcbf6778f6",
   "metadata": {},
   "source": [
    "画像サイズが変化しないことはスキップ接続や複雑な構造のモデルでテンソル同士の加減算が可能になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c58b7-9e45-4e97-b6a2-cb41f49438e1",
   "metadata": {},
   "source": [
    "## 畳み込みの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14e9a9-fd4d-4023-b675-9b82419036a4",
   "metadata": {},
   "source": [
    "手動でのパラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "012d6d06-5619-4ff3-b3f2-f53103a1e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#バイアスをゼロにする\n",
    "with torch.no_grad():\n",
    "    conv.bias.zero_()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089f9515-03f2-4536-88be-034c4a0f0ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111]],\n",
       "\n",
       "         [[0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111]],\n",
       "\n",
       "         [[0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111],\n",
       "          [0.1111, 0.1111, 0.1111]]]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4f0de35-65fe-4bfc-a08c-b2ec9f23db88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "VUQhUyEoTeVT",
    "outputId": "024b9a6a-2d2e-4863-ea9a-a26b7820192c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x345.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.figure(figsize=(10, 4.8))  # 本では省略\n",
    "ax1 = plt.subplot(1, 2, 1)   # 本では省略\n",
    "plt.title('output_padding')   # 本では省略\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)  # 本では省略\n",
    "plt.imshow(img.mean(0), cmap='gray')  # 本では省略\n",
    "plt.title('input')  # 本では省略\n",
    "#plt.savefig('Ch8_F4_PyTorch.png')  # 本では省略\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe5b4e-1501-4bd2-a497-b5a173746a67",
   "metadata": {},
   "source": [
    "convの一定の重み（フィルタ）によってボケた画像が出力された。\n",
    "畳み込みは出力ピクセル間に相関が生まれ、スムーズに画像が変化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cfd4753-f449-496d-b86b-3c17471a111d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09045477-1f06-4b11-9aab-b9430dec94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#右側のピクセルから左側のピクセルを減算するフィルタ\n",
    "#強度が異なる領域の垂直方向の境界になっているピクセルに対しては出力の値は大きな値となる。\n",
    "#一方一様な領域であれば0に近い値となる。\n",
    "\n",
    "#つまり垂直方向のエッジ検出のカーネルとなる\n",
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0]])\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6deed91-a931-4380-b63d-821af7872626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.]],\n",
       "\n",
       "         [[-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.]],\n",
       "\n",
       "         [[-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.],\n",
       "          [-1.,  0.,  1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e408be0-467d-47a9-aabe-173022526ebb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "VUQhUyEoTeVT",
    "outputId": "024b9a6a-2d2e-4863-ea9a-a26b7820192c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x345.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.figure(figsize=(10, 4.8))  # 本では省略\n",
    "ax1 = plt.subplot(1, 2, 1)   # 本では省略\n",
    "plt.title('output_padding')   # 本では省略\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)  # 本では省略\n",
    "plt.imshow(img.mean(0), cmap='gray')  # 本では省略\n",
    "plt.title('input')  # 本では省略\n",
    "#plt.savefig('Ch8_F4_PyTorch.png')  # 本では省略\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b99283-9585-48c4-9b4c-eadee1fb9783",
   "metadata": {},
   "source": [
    "ディープラーニングでは最も効果的なカーネルの値を推定する。\n",
    "学習は入力と出力の間のクロスエントロピー誤差を最小化するカーネルの値を推測していく。\n",
    "\n",
    "畳み込みニューラルネットワークは複数チャネルの画像を別の複数チャネルの画像に変換する連続した層のフィルタ群を推定することである。\n",
    "この異なるチャネルは異なる特徴量に対応する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb7802-dd64-4374-9605-f4f4f67cad8d",
   "metadata": {},
   "source": [
    "## 深さとプーリング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc64dc-7596-436d-8380-b4ffc1dbc926",
   "metadata": {},
   "source": [
    "CIFAR10の画像は小さく小さなカーネルで局所的な特徴を得た。\n",
    "大きな画像で広い範囲の構造を把握したい場合はどうすれば良いか？\n",
    "\n",
    "大きなカーネルを使用することで解決できるが、今度は元々の畳み込みの利点がなくなる。\n",
    "\n",
    "畳み込みの利点を活かし、かつ大きな範囲の構造も把握するためには畳み込み後に畳み込みを繰り返しその間にダウンサンプリングをする方法がある"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a966e-83d5-4ca1-b656-f4ba4e110393",
   "metadata": {},
   "source": [
    "## ダウンサンプリング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3473a2d4-025b-407a-b5b1-5a1123196539",
   "metadata": {},
   "source": [
    "画像を半分に縮小することは隣接している4つのピクセルを1つのピクセルにする\n",
    "\n",
    "1.アベレージプーリング\n",
    "2.マックスプーリング\n",
    "3.ストライド畳み込み\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cbe6c33-e776-41dc-a283-dcef574ae5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85042ab7-95d4-4fa8-ab0d-cfced71abaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_pooling\n",
    "#画像を半分にしたいときはインスタンス引数に2を入れる\n",
    "\n",
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape , output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbcbad-3645-49fa-9b3c-37f30fb95752",
   "metadata": {},
   "source": [
    "はじめに小さなカーネルで畳み込みを行い、局所の特徴を掴み、\n",
    "ダウンサンプリングした縮小後の画像で畳み込みを行う（元の画像で考えると倍の広い領域の特徴を掴む）\n",
    "\n",
    "1つ目のカーネルは低レベルの特徴を、2つ目のカーネルは広い領域で効果的に動作し、前の特徴量を合成した特徴量を生成する。\n",
    "\n",
    "このため複雑なケースでも対応できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0324e7d-3edb-4a85-a66c-c79b7a6e2df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Tanh()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): Tanh()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ダウンサンプリングを入れたモデル\n",
    "model = nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb4ed49c-7a95-49fb-8305-52dddb881eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出力は8チャネルの8＊8の画像\n",
    "model(img.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1996cdde-3138-4e5c-8491-8c46054cec08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Tanh()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): Tanh()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (7): Tanh()\n",
       "  (8): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出力はとりか飛行機の2値にする必要がある\n",
    "# 画像を32のベクトルにして、最後2値にする\n",
    "model = nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Linear(8 * 8 * 8, 32),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(32, 2)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df6306dc-9014-402e-bd3e-cab453fa9e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パラメータ確認\n",
    "num_list = [p.numel() for p in model.parameters()]\n",
    "sum(num_list), num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1edc5ef-b30c-4a74-8ddd-7ff4fff2097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エラーが出る\n",
    "#model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a43077c-fd2e-4a99-aa98-bdbc104d1980",
   "metadata": {},
   "source": [
    "## nn.Moduleを継承してモデルを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62504e0d-d4b8-4e91-8214-6b32bd0834e3",
   "metadata": {},
   "source": [
    "モデル内で入力が二次元から一次元へと形式が変化するような場合はnn.sequeintal()では作成できない\n",
    "（次元数が変化しないモデルを作成し。最後にLinearする手もある：キカガク参考）\n",
    "\n",
    "nn.Moduleのサブクラス(子クラス）を用いて作成する\n",
    "\n",
    "nn.Moduleを用いる場合はfoward関数を定義して、入力か出力への流れを記載する。\n",
    "backwardはtorchのテンソルでは自動でおこなってくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "525974cd-7b6c-408e-9af6-e5bfcdb3930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# バッチ数が不明のためviewの引数は-1\n",
    "# CNNの有名なモデルRESNETなどでは解像度を落としながら、チャネルを増やしていく（結果的にはサイズは縮小する）　\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffa8d1e4-af22-4a1b-9aa5-16deee5cabb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abf1170f-a58c-4e6d-8bf8-abcf5bca6091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1294, -0.1205]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f78f51a3-6e98-4e1a-b600-4f758749b382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): Tanh()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): Tanh()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (act3): Tanh()\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb71a11-4830-4476-b328-bd7ae5571f55",
   "metadata": {},
   "source": [
    "## functional API\n",
    "\n",
    "パラメータが不要なサブモジュールも上の例ではインスタンス化して登録している。\n",
    "pytorchでは「内部状態を持たない」といういみのfanctonalAPIが存在し、入力値を引数に入れると出力値が決定するモジュールがある。\n",
    "\n",
    "nn.Linear には　nn.fanctional.linear 　　重みとバイアスと入力値を引数に入れて出力値が決まる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3118a26-75e2-4190-b897-435de7f93122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9eef8c95-20d5-4d34-86eb-f828c36a53bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0529,  0.0507]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aef8c4-9566-4a48-83b0-6fdc6f6e3054",
   "metadata": {},
   "source": [
    "## 畳み込みニューラルネットの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e0da96-8781-4e56-96e6-138a62557fe8",
   "metadata": {},
   "source": [
    "ネットワークは外側がエポック、内側がバッチを取り出すDataLoaderによって二重にネストされている\n",
    "\n",
    "各訓練ループは\n",
    "\n",
    "１．入力をモデルに与える\n",
    "\n",
    "２．損失を計算する\n",
    "\n",
    "３．勾配をゼロにする（リセット）\n",
    "\n",
    "４．loss.backfoward()ですべてのパラメータの損失に対する勾配を計算\n",
    "\n",
    "５．オプティマイザで損失を低下する方向に更新\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "958b331a-e4db-489f-9210-8a5ec63beab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lossまでの確認\n",
    "img, label = cifar2[0]\n",
    "label = torch.tensor([label])\n",
    "label.shape\n",
    "#labelはバッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a0a2dc4-e0ba-4541-ba1e-d53189b40689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(img.unsqueeze(0))\n",
    "output.shape\n",
    "#outputは バッチ　＊　答えの種類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dce09518-4155-4737-bc3d-c23934dd02cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6427, grad_fn=<NllLossBackward0>) 0.6426792144775391\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#確率が高い方のその値とラベルとの損失\n",
    "loss = loss_fn(output, label)\n",
    "print(loss, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f581d92d-a3e7-4c13-b2f0-8b55d7d767f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # <1>\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):  # <2>\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  # <3>\n",
    "            outputs = model(imgs)  # <4>\n",
    "            loss = loss_fn(outputs, labels)  # <5>\n",
    "            optimizer.zero_grad()  # <6>            \n",
    "            loss.backward()  # <7>\n",
    "            optimizer.step()  # <8>\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  # <10>\n",
    "            # <1>\n",
    "# Pythonに含まれているdatetimeモジュールを使用 \n",
    "# \n",
    "# <2>\n",
    "# 0からではなく1からn_epochsまで数字を振ったエポックに対するループ\n",
    "# <3>\n",
    "# データローダーが作成したバッチの中のデータセットに対するループ\n",
    "# <4>\n",
    "# モデルにバッチを投入し、…\n",
    "# <5>\n",
    "# … そして最小化したい損失を計算を行う。\n",
    "# <6>\n",
    "# 直近のラウンドの勾配を取り除いたあとに…\n",
    "# <7>\n",
    "# … バックワード処理を行う。 \n",
    "# つまり、ネットワークに学習して欲しいすべての パラメーターの勾配を計算します。\n",
    "# <8>\n",
    "# モデルを更新\n",
    "# <9>\n",
    "# エポックをまたいで損失を合算。 \n",
    "# 勾配の情報を除くため、損失の値を.item()を用いて \n",
    "# Pythonの数値に変形するということを覚えておきましょう。 \n",
    "# <10>\n",
    "# 訓練用のデータローダーの長さで除算し、バッチあたりの平均損失を得ます。 \n",
    "# これは合計値よりも直感的な尺度ですね。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986590e-e784-4fe6-952a-37010adbe81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:20:48.352391 Epoch 1, Training loss 0.5983713366043796\n",
      "2022-08-04 07:21:06.936294 Epoch 10, Training loss 0.32304165659436757\n",
      "2022-08-04 07:21:28.214782 Epoch 20, Training loss 0.28603252607166385\n",
      "2022-08-04 07:21:48.568826 Epoch 30, Training loss 0.25668408996929787\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)  # <1>\n",
    "\n",
    "model = Net()  #  <2>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
    "\n",
    "training_loop(  # <5>\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "# <1>\n",
    "# DataLoaderがcifar2のデータセットのサンプルをバッチ化します。 \n",
    "# また、データセットからサンプルを取得する順番をランダムにシャッフルしています。 \n",
    "# <2>\n",
    "# ネットワークをインスタンス化し、…\n",
    "# <3>\n",
    "# … 扱った確率的勾配降下の最適化関数を使用し…\n",
    "# <4>\n",
    "# … 7.10節で扱った交差エントロピー損失を使用。\n",
    "# <5>\n",
    "# 先程定義した訓練ループを呼び出す。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b87155-3a99-4ca6-8cdb-a17dafc6efee",
   "metadata": {},
   "source": [
    "訓練の損失は低下したがそれだけでは評価できない\n",
    "\n",
    "評価指標が必要であるため、正解率で確認してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae15868-db04-4210-9676-94ab31275624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.88\n",
      "Accuracy val: 0.85\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "import collections\n",
    "\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict={}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # パラメータの更新は不要のためlossは確認しない、勾配も不要\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada9fc1e-3893-4695-a7a3-fde7e9da1d42",
   "metadata": {},
   "source": [
    "##　モデルの保存と読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b1954-b534-42d9-8712-95bb810b6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # モデルの保存\n",
    "data_path = '.'\n",
    "\n",
    "torch.save(model.state_dict(), data_path + \"birds_vs_airplanes.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ad7de-0fa2-4fa3-974f-3e4325d38aff",
   "metadata": {},
   "source": [
    "この方法でモデルを保存したときはモデル内のパラメータと（重みとバイアス）であって、\n",
    "モデルの構造は保存されていない。\n",
    "\n",
    "読み込み時にモデルは同一のモデルをインスタンス化してパラメータを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44448ddb-fa62-49b0-a5f5-89c0fefa6bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # モデルの読み込み\n",
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load(data_path + 'birds_vs_airplanes.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4f9c5-099e-4d42-b9fa-dd2f0b1de2f1",
   "metadata": {},
   "source": [
    "## GPU上での訓練\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81946a-8824-4f24-b8c2-cc70ec6bc734",
   "metadata": {},
   "source": [
    ".toメソッドを使えばテンソルをGPUへ移動できる。モデルのパラメータもGPUに移し計算をGPU上で行う。\n",
    "\n",
    "Module.toはそのインスタンスそのものが移動する。\n",
    "\n",
    "Tensor.toは別メモリ上での処理となり、あらたなテンソルが返される\n",
    "\n",
    "モデルは適当なデバイスにパラメータを移してからOptimaizerを作成するのがよい。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cdca4-4559-40e2-9070-2b6c77ded67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "\n",
    "print(f'Training on device {device}.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9b575-650d-4523-ad10-3a1b9c836b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUでの学習でも対応\n",
    "# 全てのパラメータがGPUに無い場合はエラー（一部GPUでの計算は非対応）\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device) \n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc499cbd-abb3-40a9-868e-067bf79d6589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:21:52.230299 Epoch 1, Training loss 0.6072637319185172\n",
      "2022-08-04 07:22:11.573403 Epoch 10, Training loss 0.32538400372122506\n",
      "2022-08-04 07:22:33.067150 Epoch 20, Training loss 0.2949707527069529\n",
      "2022-08-04 07:22:54.080757 Epoch 30, Training loss 0.2707322500883394\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b53b8d01-9a5a-4010-be0c-6eec8c92de22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EeffUEkETeW7",
    "outputId": "c9b9845d-0526-41f8-e00e-c04e064d155d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorchではネットワークの重み等の読み込み時は保存時のデバイスに読み込もうとする。\n",
    "# ネットワークの重みを読み込むデバイスと保存されているデバイスが同じなのか事前には分からないため指示する　map_loacation\n",
    "loaded_model = Net().to(device=device)\n",
    "loaded_model.load_state_dict(torch.load(data_path\n",
    "                                        + 'birds_vs_airplanes.pt',\n",
    "                                        map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b33b1e-1034-489d-ab20-a4c0ccf2efba",
   "metadata": {},
   "source": [
    "##　モデルの改善：幅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b833710-8056-41a5-be86-8c88438f454c",
   "metadata": {},
   "source": [
    "記憶容量の追加時にハードコーティングを避けるためには、initにパラメータを渡す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f9c380d-f7ea-4161-827c-7aa1571f01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWidth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1 \n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d427dbc-5502-49a9-85e0-2e91b8437718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:22:58.337797 Epoch 1, Training loss 0.5586554305568622\n",
      "2022-08-04 07:23:36.593919 Epoch 10, Training loss 0.31862089806681226\n",
      "2022-08-04 07:24:19.412632 Epoch 20, Training loss 0.2749388356497333\n",
      "2022-08-04 07:25:07.377365 Epoch 30, Training loss 0.24361977626563638\n",
      "Accuracy train: 0.88\n",
      "Accuracy val: 0.78\n"
     ]
    }
   ],
   "source": [
    "model = NetWidth(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "all_acc_dict[\"width\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc797468-d440-4a89-8be2-3ab4b826c9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38386"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8561d567-1686-4db1-808a-ac92b2c8c235",
   "metadata": {},
   "source": [
    "モデル内の容量が増加するほどモデルが管理できる入力の可能性は高くなる。\n",
    "しかし同時に不要な側面を記憶するパラメータをモデルが多数使用することになり、過学習が起きやすい。\n",
    "\n",
    "過学習にはサンプルサイズの拡大、DataAugmentationが有効だが、モデルレベルでの制御法もある"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f52f6-e837-482a-94e9-e6d81aa48c98",
   "metadata": {},
   "source": [
    "## 損失時に改善　正則化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6d3ea-9002-4167-9188-21a126306bf7",
   "metadata": {},
   "source": [
    "損失に正則化項（重みパラメータを足したもの）を加えることで、大きな値の重みへのペナルティになる。\n",
    "損失関数はより滑らかになり、個々のサンプルに過剰に適合することを防ぐ。\n",
    "\n",
    "L2：モデル内の重みの二乗をすべて足したもの\n",
    "重みの減衰（現在の値に比例した量だけ各重みを減衰させる）\n",
    "\n",
    "L1：モデル内の重みの絶対値をすべて足したもの\n",
    "重みを0に近づけるため不要なパラメータを無くす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8ab18c1-90af-44cb-8526-b0b8a2c7344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs +1 ):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            l2_lambda = 0.01\n",
    "            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "            #l1はpoe(2.0)をabs()\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch, loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f1bc5b6-d108-42b6-a77d-aa23392ea245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:25:13.256518 Epoch 1, Training loss 0.8081606440483384\n",
      "2022-08-04 07:25:36.446835 Epoch 10, Training loss 0.47865571527724055\n",
      "2022-08-04 07:26:12.124469 Epoch 20, Training loss 0.4170774420735183\n",
      "2022-08-04 07:26:35.607158 Epoch 30, Training loss 0.38696237677221845\n",
      "Accuracy train: 0.87\n",
      "Accuracy val: 0.84\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop_l2reg(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "all_acc_dict[\"l2 reg\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69811006-8552-44c5-8596-a319c6af1611",
   "metadata": {},
   "source": [
    "## ドロップアウト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99315bc-27a6-44f9-98c8-7568e1f48d38",
   "metadata": {},
   "source": [
    "ネットワーク上の出力をランダムの割合でゼロにする\n",
    "各反復で異なるニューロンの形状のわずかに異なるモデルが作成されるため、モデル内のニューロンが記憶プロセスになることを防ぐ。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9347e7-0036-4f52-b16c-00245964bb90",
   "metadata": {},
   "source": [
    "このドロップアウトは訓練時のみ有効であり、推論時はモードを切り替えて全パラメータを使用する。\n",
    "\n",
    "model.train()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "で切り替え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aadbac98-3189-476c-9b68-424af263636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2444fb8-df7a-402a-b971-c1b5598b3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:26:41.772915 Epoch 1, Training loss 0.5628887039081306\n",
      "2022-08-04 07:27:22.552239 Epoch 10, Training loss 0.36985790663084406\n",
      "2022-08-04 07:28:06.834297 Epoch 20, Training loss 0.34125151252670655\n",
      "2022-08-04 07:28:51.544297 Epoch 30, Training loss 0.3230181481618031\n",
      "Accuracy train: 0.86\n",
      "Accuracy val: 0.84\n"
     ]
    }
   ],
   "source": [
    "model = NetDropout(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "\n",
    "all_acc_dict[\"dropout\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f142ec20-843a-42e3-bdc6-92639c065da0",
   "metadata": {},
   "source": [
    "## バッチ正則化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f106b6d-151f-41dc-96c0-554c97a5f59c",
   "metadata": {},
   "source": [
    "活性化に対する入力を特定の分布内にリスケールする。\n",
    "入力が活性化関数の飽和部分へ極端に移動することを防ぎ訓練が遅くなることを防ぐ。\n",
    "\n",
    "ミニバッチごとにネットワークの中間地点で入力値の平均値と標準偏差を使用して中間入力の大きさにシフトする。\n",
    "\n",
    "正則化とデータオーギュメンテーションの意味がある\n",
    "\n",
    "基本的には活性化関数の前に使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4917a-dfb4-4f0a-9e4d-53f11f505746",
   "metadata": {},
   "source": [
    "推論時はモードを切り替えることで、訓練時のデータセット全体の平均値と標準偏差を毎回使用するようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cb0a6aa-8d03-4729-8335-86efbe5cf32e",
   "metadata": {
    "id": "aaVSP0vGTeXl"
   },
   "outputs": [],
   "source": [
    "class NetBatchNorm(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, \n",
    "                               padding=1)\n",
    "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.conv2_batchnorm(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82014495-f111-471e-a2c9-e1cf2c42168c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "tpjdjqfaTeXo",
    "outputId": "c846e757-3f21-491d-e9cf-6e5dbb9c7f75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:29:00.187139 Epoch 1, Training loss 0.4640124616729226\n",
      "2022-08-04 07:29:51.728797 Epoch 10, Training loss 0.2723110207137029\n",
      "2022-08-04 07:30:48.898004 Epoch 20, Training loss 0.21426195174360732\n",
      "2022-08-04 07:31:46.353945 Epoch 30, Training loss 0.17343610022098396\n",
      "Accuracy train: 0.88\n",
      "Accuracy val: 0.85\n"
     ]
    }
   ],
   "source": [
    "model = NetBatchNorm(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "all_acc_dict[\"batch_norm\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844e24c-cd96-4ffd-9939-e0c250760b09",
   "metadata": {},
   "source": [
    "## モデル改善：深さ　スキップ接続"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd5ab5-4cbc-44e8-a670-991790dff5e3",
   "metadata": {},
   "source": [
    "接続の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905db45-a3d8-45cb-b7f8-052b34de4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_a = torch.randn(2,1)\n",
    "batch_b = torch.randn(2,1)\n",
    "batch_a, batch_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a34d23-9c93-43da-a24a-1622550b012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_a + batch_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00238ca1-c6d7-49b7-bf7e-6cf976c65f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.empty(3, 5)\n",
    "nn.init.constant_(w, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde2616-4065-4eea-8370-2dfc3ef76abd",
   "metadata": {},
   "source": [
    "ある層の活性化後のの出力を次の層の線形処理後の入力に追加する。\n",
    "\n",
    "このことで深部の損失の勾配に対する各パラメータの寄与がより直接的になる。\n",
    "序盤のパラメータの収縮の観点で効果的である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68b54973-9567-4584-bda8-b5518f1f5716",
   "metadata": {
    "id": "NjWrXybDTeX2"
   },
   "outputs": [],
   "source": [
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdd85db3-d0ab-492d-b221-99b400c54734",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "KfgqWhcwTeX6",
    "outputId": "fafaf0f3-4a4f-497a-ce84-702e25bbda0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:55:33.483912 Epoch 1, Training loss 0.6428604524606353\n",
      "2022-08-04 07:56:09.220229 Epoch 10, Training loss 0.32137808602326995\n",
      "2022-08-04 07:56:48.922005 Epoch 20, Training loss 0.27012127182286255\n",
      "2022-08-04 07:57:29.275451 Epoch 30, Training loss 0.23492220419037874\n",
      "Accuracy train: 0.89\n",
      "Accuracy val: 0.81\n"
     ]
    }
   ],
   "source": [
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 30,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "all_acc_dict[\"res\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f3ef5-cb5c-4d6e-9aa9-50508b9567d4",
   "metadata": {},
   "source": [
    "## ディープなモデルを作成するためには"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a504ca5-c4ca-4de6-9d14-d7a50b87c624",
   "metadata": {},
   "source": [
    "標準的な戦略としては（conv2d,batchnorm,Relu,スキップ接続）のブロックを作成して、\n",
    "for1ループで動的に繰り返す方法がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a32a8792-a9c6-4435-bd2c-7e923c485eb5",
   "metadata": {
    "id": "lNqv3CZgTeX9"
   },
   "outputs": [],
   "source": [
    "#ブロックの作成\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        #継承時にsuperの引数は不要だが、多重継承の時に予期せぬ継承がされる可能性があり、引数に指定する\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,padding=1, bias=False)  # <1>\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,nonlinearity='relu')  # <2>\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "\n",
    "# <1>\n",
    "# BatchNorm層はバイアスの影響を消し去るため、慣例的にバイアスは省いています。 \n",
    "# <2>\n",
    "# ResNetの論文で計算されている標準偏差を持つ正規の乱数を用いたカスタマイズの初期化処理 kaiming_normal_initializes を使用します。 \n",
    "# なお、初期状態では、バッチ正規化処理は平均0で分散0.5の出力分布を生成するように初期化されます。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6aedc1-e2f1-43e1-9bbc-1cf1370d9e36",
   "metadata": {},
   "source": [
    "ディープに作るためには\n",
    "\n",
    "resbloksにnn.Sequentialを定義して、指定数＊Resblockを入れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41bad8c2-bfad-43ed-82d0-6ee8946b40d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> [ResBlock(\n",
      "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), ResBlock(\n",
      "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), ResBlock(\n",
      "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "#リスト\n",
    "a=(3 * [ResBlock(n_chans=32)])\n",
    "print(type(a),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "609a8afc-ad67-4d20-846a-392f00d70ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ResBlock(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): ResBlock(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): ResBlock(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resblocks = nn.Sequential(\n",
    "           * (3 * [ResBlock(n_chans=32)]))\n",
    "resblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34130157-1722-4f5e-b2b3-8ba566d15c44",
   "metadata": {
    "id": "rRHc8xfWTeYD"
   },
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ac5e2-e059-4ac2-900b-009b5c06c06d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "TkiMOWJfTeYF",
    "outputId": "b426481a-78c9-4e14-f3e5-522124599bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 08:22:35.397013 Epoch 1, Training loss 1.2335678866714428\n"
     ]
    }
   ],
   "source": [
    "model = NetResDeep(n_chans1=32, n_blocks=100).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "all_acc_dict[\"res deep\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e298f23-4f64-4144-b071-8400bf068719",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "X8ZExdRETeYN",
    "outputId": "7c0e9564-e4d1-446b-93c6-2bed99a40df1"
   },
   "outputs": [],
   "source": [
    "trn_acc = [v['train'] for k, v in all_acc_dict.items()]\n",
    "val_acc = [v['val'] for k, v in all_acc_dict.items()]\n",
    "\n",
    "width =0.3\n",
    "plt.bar(np.arange(len(trn_acc)), trn_acc, width=width, label='train')\n",
    "plt.bar(np.arange(len(val_acc))+ width, val_acc, width=width, label='val')\n",
    "plt.xticks(np.arange(len(val_acc))+ width/2, list(all_acc_dict.keys()),\n",
    "           rotation=60)\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0.7, 1)\n",
    "plt.savefig('accuracy_comparison.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c75115-ec04-497d-a713-091838fca9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb1351-e98e-42fc-884f-f660ee55c17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bde67-af5e-46cb-9f2a-639e4cce72a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2192de4-3741-419f-9cf7-327d45c23dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99025ec1-8b60-4b04-b9a8-1ecc2f872ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df127cd7-a3b3-45e4-8653-c414224caad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
